\section{Variations in presentation}

\subsection{A little history}
Haskell was the first programming language to popularize the notion of
monad as a structuring technique for functional programming. There
were several key ideas that went into the $\Haskell$ packaging of the
idea. One was to treat the core elements that make up a monad more or
less \emph{directly} without appeal to category theory -- the branch
of mathematics where the notion originated. This is considerably
easier to do in a functional programming language because the ambient
language can be thought of as a category; thus, for the average
programmer there is no need to refer to categories, in general, but
only to the ``universe'' of programs that can be written in the
language at hand. Then, because Haskell already has a notion of
parametric polymorphism, a monad's most central piece of data is a
parametric type constructor, say $T$.

\paragraph{Haskell's monad API}
Given such a type constructor, you only need a pair of maps (one of
which is higher order). Thus, in $\Haskell$ a monad is presented in
terms of the following data

\begin{itemize}
  \item a parametric type constructor, \lstinline[language=Haskell]!T! a
  \item a \lstinline[language=Haskell]!return! map enjoying the
    signature \lstinline[language=Haskell]!return :: a -> T a!
  \item a \lstinline[language=Haskell]!bind! map enjoying the
    signature \lstinline[language=Haskell]!bind : T a -> (a -> T b) -> T b!
\end{itemize}

In $\Haskell$ these elements can be collected inside a
\lstinline[language=Haskell]!typeclass!. Resulting in a declaration of
the form

% TODO : add typeclass
\begin{lstlisting}[captionpos=b,language=Haskell,caption=monad typeclass]
  typeclass Monad T a where
   return :: a -> T a
   bind :: T a -> (a -> T b ) -> T b
\end{lstlisting}

Now, it's not enough to simply have this collection of pieces. The
pieces have to fit together in a certain way; that is, they are
subject to the following laws:

\begin{itemize}
  \item \lstinline[language=Haskell]!return (bind a f)! $\equiv$ \lstinline[language=Haskell]!f a! %[Left identity]
  \item \lstinline[language=Haskell]!bind m return! $\equiv$ \lstinline[language=Haskell]!m! %[Right identity]
  \item \lstinline[language=Haskell]!bind (bind m f) g! $\equiv$ \lstinline[language=Haskell]!bind m (\ x -> bind (f x) g)! %[Associativity]
\end{itemize}

\paragraph{Do-notation}
One of the driving motivations for this particular formulation of the
concept is that it makes it very easy to host a little DSL inside the
language. The syntax and semantics of the DSL is simultaneously given
by the following procedure for de-sugaring, i.e. translating
expressions in the DSL back to core \texttt{Haskell}.

\begin{lstlisting}[language=Haskell,mathescape=true]
do { x } $=$ x
 
do { x ; <stmts> }
  $=$ bind x (\_ -> do { <stmts> })
 
do { v <- x ; <stmts> }
  $=$ bind x (\v -> do { <stmts> }) 

do { let <decls> ; <stmts> }
  $=$ let <decls> in do { <stmts> }
\end{lstlisting} 

The assignment-like operation extends to full pattern matching with

\begin{lstlisting}[language=Haskell,mathescape=true]
  do { p <- x ; <stmts> }
  $=$ let f p = do { <stmts> }
              f _     = fail "..."
      in bind x f
\end{lstlisting}

On the face of it, the notation provides both a syntax and a semantics
reminiscent of the standard side-effecting operations of mainstream
imperative languages. In presence of polymorphism, however, these
instruments are much more powerful. These operations can be
\emph{systematically} ``overloaded'' (meaning the overloaded
definitions satisfy the laws above). This allows to systematically use
the notation for a wide variety of computations that all have some
underlying commonality. Typical examples include I/O, state
management, control flow (all three of which all bundle up in
parsing), and also container navigation and manipulation. It gets
better for many of the tools of mathematics that are regularly the
subject of computer programs such probability distributions,
integration, etc., also have presentations as monads. Thus, innocent
examples like this one

\begin{lstlisting}[language=Haskell]
  do { putStrLn "Enter a line of text:";
       x <- getLine;
       putStrLn ("you wrote: " ++ x) }
\end{lstlisting}

as might be found in some on-line tutorial on monads belie the potency
of this combination of ideas.

\paragraph{for-comprehensions}
Unlike $\Haskell$, $\Scala$ does not reify the notion of monad under a
\lstinline[language=Scala]!trait!, the language's equivalent of
$\Haskell$'s \lstinline[language=Haskell]!typeclass!. Instead the
systematic means of de-sugaring
\lstinline[language=Scala]!for!-notation and polymorphic
interpretations of \lstinline[language=Scala]!flatMap!, etc are the
effective definitions of the notion in $\Scala$.

The basic \texttt{Scala} construct looks like

\begin{lstlisting}[language=Scala]
  for( p <- e [; p <- e] [p = e] [if t] ) yield { e }
\end{lstlisting}

and the de-sugaring looks like

\begin{lstlisting}[language=Scala,mathescape=true]
  for( x <- expr$_1$ ; y <- expr$_2$ ; <stmts> ) yield expr$_3$

  $=$

  expr$_1$ flatMap( x => for( y <- expr$_2$; <stmts> ) yield expr$_3$ )

  for( x <- expr$_1$ ; y = expr$_2$ ; <stmts> ) yield expr$_3$
  
  $=$

  for( ( x, y ) <- for ( x <- expr$_1$ ) yield ( x, expr$_2$ ); <stmts> )
  yield expr$_3$

  for( x <- expr$_1$ if pred ) yield expr$_2$ 

  $=$

  expr$_1$ filter ( x => pred ) map ( x => expr$_2$ )    
\end{lstlisting}

Again, general pattern matching is supported in assignment-like statements.

\begin{lstlisting}[language=Scala,mathescape=true]
  for( p <- expr$_1$ ; <stmts> ) yield expr$_2$ 

  $=$

  expr$_1$ filter {
    case p => true
    case _ => false
  } flatMap {
    p => for( <stmts> ) yield expr$_2$
  }
\end{lstlisting}

This means, therefore, that we have the following correspondence

% TODO write down the $\Haskell$/$\Scala$ monad correspondence

\subsection{A little more history}

If one were to reify the notion in $\Scala$ there are several design
choices -- all of which endure some desiderata. Following the original
presentation developed in category theory, however, has some crucial
advantages:

\begin{itemize}
  \item intuition
  \item correspondence to previously existing structures
  \item decomposition of the requirements 
\end{itemize}

which we explore in some detail here.

\subsubsection{Intuition: Monad as container}

As we will see the notion of monad maps nicely onto an appropriately
parametric notion of container. From this point of view we can imagine
a container ``API'' that has three basic operations. 
\paragraph{Shape of the container} The first of these is a
\emph{parametric} specification of the \emph{shape} of the
container. Examples of container shapes include: \lstinline[language=Scala]!List[A]!,
\lstinline[language=Scala]!Set[A]!, \lstinline[language=Scala]!Tree[A]!, etc. At the outset we remain
uncommitted to the particular shape. The API just demands that
there is some shape, say \lstinline[language=Scala]!S[A]!.
\paragraph{Putting things into the container} The next operation is
very basic, it says how to put things into the container. To align
with a very long history, we will refer to this operation by the name
\lstinline[language=Scala]!unit!. Since the operation is supposed to allow us to put
elements of type \lstinline[language=Scala]!A! into containers of shape \lstinline[language=Scala]!S[A]!, we
expect the signature of this operation to be \lstinline[language=Scala]!unit : A => S[A]!.
\paragraph{Flattening nested containers} Finally, we want a generic
way to flatten nested containers. Just like there's something
fundamentally the same about the obvious way to flatten nested lists
and nested sets, we ask that the container API provide a canonical way
to flatten nested containers. If you think about it for a moment, if a
container is of shape, \lstinline[language=Scala]!S[A]!, then a nested container will be
of shape, \lstinline[language=Scala]!S[S[A]]!. If history demands that we call our
flattening operation \lstinline[language=Scala]!mult!, then our generic flatten operation
will have signature, \lstinline[language=Scala]!mult : S[S[A]] => S[A]!.

\subsubsection{Preserving connection to existing structure: Monad as
  generalization of monoid}

Programmers are very aware of data structures that support a kind of
concatenation operation. The data type of \lstinline[language=Scala]!String! is a perfect
example. Every programmer expects that the concatenation of a given
\lstinline[language=Scala]!String!, say \lstinline[language=Scala]!s!, with the empty \lstinline[language=Scala]!String!,
\lstinline[language=Scala]!""! will return a result string equal to the original. In
code, \lstinline[language=Scala]! s.equals( s + "" ) == true !. Likewise, string
concatenation is insensitive to the order of operation. Again, in
code, \lstinline[language=Scala]! (( s + t ) + u).equals( s + ( t + u ) ) == true !.

Most programmers have noticed that these very same laws survive
polymorphic interpretations of \lstinline[language=Scala]!+!, \lstinline[language=Scala]!equals! and the
``empty'' element. For example, if we substituted the data type
\lstinline[language=Scala]!Integer! as the base type and used integer addition, integer
equality, and \lstinline[language=Scala]!0! as the empty element, these same code
snippets (amounting assertions) would still work.

Many programmers are aware that there is a very generic underlying
data type, historically referred to as a \emph{monoid} defined by
these operations and laws. In code, we can imagine defining a
\lstinline[language=Scala]!trait! in $\Scala$ something like

\begin{lstlisting}[language=Scala]
  trait Monoid {
    def unit : Monoid
    def mult( that : Monoid ) 
  }
\end{lstlisting}

This might allow \emph{views} of \lstinline[language=Scala]!Int! as a monoid as in

\begin{lstlisting}[language=Scala]
  class MMultInt extends Int with Monoid {
    override def unit = 1
    override def mult( that : Monoid ) = this * that
    }
\end{lstlisting}

except for the small problem that \lstinline[language=Scala]!Int! is
\lstinline[language=Scala]!final! (illustrating an important
difference between the adhoc polymorphism of \texttt{Haskell}'s
\lstinline[language=Haskell]!typeclass! and \texttt{Scala}'s
\lstinline[language=Scala]!trait!).

Any solution will depend on type parametrization. For example

\begin{lstlisting}[language=Scala]
  trait Monoid[Element] {
    def unit : Element
    def mult( a : Element, b : Element ) 
  }
\end{lstlisting}

and corresponding view of \lstinline[language=Scala]!Int! as a monoid.

\begin{lstlisting}[language=Scala]
  class MMultInt extends Monoid[Int] {
    override def unit : Int = 1
    override def mult( a : Int , b : Int ) = a * b
  }
\end{lstlisting}

This parametric way of viewing some underlying data structure is
natural both to the modern programmer and the modern
mathematician. Both are quite familiar with and make extensive use of
overloading of this kind. Both are very happy to find higher levels of
abstraction that allow them to remain DRY when the programming demands
might cause some perspiration. One of the obvious places where
repetition is happening is in the construction of view. Consider
another view of \lstinline[language=Scala]!Int!

\begin{lstlisting}[language=Scala]
  class MAddInt extends Monoid[Int] {
    override def unit : Int = 0
    override def mult( a : Int , b : Int ) = a + b
  }
\end{lstlisting}

It turns out that there is a lot of machinery that is common to
defining a view like this for any given data type. Category theorists
realized this and recognized that you could reify the \emph{view}
which not only provides a place to refactor the common machinery, but
also to give it another level of polymorphism. Thus, a category
theorist's view of the monad API might look something like this.

\begin{lstlisting}[language=Scala]
  trait Monad[Element,M[_]] {
    def unit( e : Element ) : M[Element]
    def mult( mme : M[M[Element]] ) : M[Element] 
  }
\end{lstlisting}

The family resemblance to the \lstinline[language=Scala]!Monoid! API
is not accidental. The trick is to bring syntax back into the picture. Here's an example.

\begin{lstlisting}[language=Scala]
  case class MonoidExpr[Element]( val e : List[Element] )
  class MMInt extends Monad[Int,MonoidExpr] {
    override def unit( e : Int ) = MonoidExpr( List( e ) )
    override def mult( mme : MonoidExpr[MonoidExpr[Int]] ) =
    mme match {
      case MonoidExpr( Nil ) =>
         MonoidExpr( Nil )
      case MonoidExpr( mes ) => 
         MonoidExpr(
            ( Nil /: mes)( 
               { ( acc, me ) => me match { 
                   case MonoidExpr( es ) => acc +++ es 
                 } 
               } 
             )
         )
    }
  }
\end{lstlisting}

While it's clear that \lstinline[language=Scala]!unit! turns
\lstinline[language=Scala]!Int!s into integer expressions, what the
operation \lstinline[language=Scala]!mult! is doing is canonically
flattening nested expressions in a way the exactly parallels the
flattening of nest arithmetic addition expressions. For a broad class
of monads, this is the paradigmatic behavior of
\lstinline[language=Scala]!mult!. The fact that monads are
characterized by a generic interpretation of flattening of nested
structure, by the way, makes the choice of the term
\lstinline[language=Scala]!flatMap! particularly appropriate.

\paragraph{Associativity as flattening}
Looking at it from the other way around, one of the properties of a
monoid is that it's binary operation, its
\lstinline[language=Scala]!mult!, is associative. The actual content of
the notion of associativity is that order of grouping doesn't make any
difference. In symbols, a binary operation, $*$, is associative when
$a*(b*c) = (a*b)*c$. This fact gives us the right to erase the parens
and simply write $a*b*c$. In other words, associativity is
flattening. A similar connection can be made for
\lstinline[language=Scala]!unit! and the identity of a monoid. One
quick and dirty way to see this is that since we know that $a*e=a$
(when $e$ is the unit of the monoid) then the expression $a*e$
effectively nests $a$ in a
\lstinline[language=Scala]!MonoidExpr!. That's the ``moral'' content
of the connection between the two notions of unit.

\paragraph{Syntax and containers}
The crucial point in all of this is that \emph{syntax is the only
  container we have for computation}. What do we mean by this? Back
when Moggi was crafting his story about the application of the notion
of monad to computing he referred to monads as ``notions of
computation''. What he meant by that was that monads reify computation
(such as I/O or flow of control or constructing data structures) into
``objects''. Computation as a phenomenon, however, is both dynamic and
(potentially) infinitary. At least as we understand it today, it's not
in the category of widgets we can hold in our hand like an apple or an
Apple $\texttrademark$ computer. All we can do is \emph{point} to it,
indicate it in some way. Syntax, it turns out, is our primary means of
signifying computation. 

\paragraph{Bracing for \texttt{XML}}
In this connection it is useful to make yet another connection to a
ubiquitous technology, namely \texttt{XML}. As a segue, notice that we
can always write a binary operation in prefix notation as well as
infix. That is, whatever we could write at $a*b$ we could just as
easily write as $*(a,b)$. The flattening property of associativity
says we can drop nesting such as $*(a,*(b,c))$ in favor of
$*(a,b,c)$. In this sense, the syntax of braces is a kind of generic
syntax for monoids and monads. If we introduce the notion of
``colored'' braces, this becomes even more clear at the lexicographic
or notational level. So, instead of $*(a,b,c)$ we'll mark the
``color'' of the braces like so: $(*| ... |*)$, where $*$ can be any
color. Then, at the level of monoid the unit is the empty braces, $(*|
|*)$, while at the level of the monad the unit places the element, say
$a$, in between the braces: $(*| a |*)$. The conceptual connection
between the two variations of the operation now becomes clear: writing
$a*e$ is the same as writing $*(a,e)$ which is the same as writing
$(*| a , (*| |*) |*)$, which canonically flattens into $(*| a |*)$.

Now, anyone who's spent any time around \texttt{XML} can see where
this is headed. At a purely syntactic, lexicographic level we replace
round brackets with angle brackets and we have exactly \texttt{XML}
notation for elements. In this sense, \texttt{XML} is a kind of
universal notation for monads. The only thing missing from the
framework is a means to associate operations to unit and mult, i.e. to
inserting content into elements and flattening nested
elements. \texttt{Scala}'s specific support for \texttt{XML} puts it
in an interesting position to rectify this situation.

\paragraph{The connection with set-comprehensions}
Finally, since we've gone this far into it, we might as well make the
connection to comprehensions. Again, let's let notation support our
intuitions. The above discussion should make it clear that its not the
particular shape of the brace that matters, but the action of
``embracing'' a collection of elements that lies at the heart of the
notion. So, it's fine if we shift to curly braces to be
suggestive. Thus, we are looking at a formalism that allows us to
polymorphically ``collect'' elements between braces, like $\{*| a, b, c |*\}$.

This is fine for finite collections, but what about infinitary
collections or collections of elements selected programmatically,
rather than given explicitly. The set theoretic notation was designed
specifically for this purpose. When we have an extant set of elements
that we can give explicitly, we simply write $\{ a_1, a_2, a_3, ... \}$.
When we have a potentially infinitary collection of elements, or
elements that are selected on the basis of a condition, then we write
$\{ pattern \in S \; | \; condition \}$. The idea of monad as comprehension
recognizes that these operations of collecting, pattern matching and
selection on the basis of a condition can be made \emph{polymorphic}
using monads. Notationally, we can denote the different polymorphic
interpretations by the ``color'' of the brace. In other words, we are
looking at a shift of the form
\begin{itemize}
  \item $\{ a_1, a_2, a_3, ... \} \mapsto \{*| a_1, a_2, a_3, ... |*\}$
  \item $\{ pattern \; \in \; S \;|\; condition |\} \mapsto \{*| pattern \in S \; | \; condition |*\}$
\end{itemize}
to build into our notation an explicit representation of the fact that
the operation of collection, pattern matching and filtering on the
basis of predicate are polymorphic.

Often times, good mathematics, like good programming is really about
the design of good notation -- it's about DSLs! In this case, the
notation is particularly useful because it begs the question of the
language of patterns and the language of conditions -- something that
Wadler's original paper on monads as generalized comprehensions did
not address. This is a theme to which we will return at the end of the
book when we address search on a semantics basis. For now, the central
point is to understand how monad as container and monad as
generalization of monoid are actually views of the same underlying
idea.

Now, just to make sure the connection is absolutely explicit, there is
a one-for-one correspondence between the polymorphic set-comprehension
notation and the \lstinline[language=Scala]!for!-comprehension
notation of \texttt{Scala}. The correspondence takes
$\{*| pattern \in S \; | \; condition |*\}$ to

\begin{lstlisting}[language=Scala,mathescape=true]
  for( x <- $S$ if $condition$ ) yield {
    x match { case $pattern$ => x }
  }
\end{lstlisting}

As the \texttt{Scala} type checker will explain, this translation is
only approximate. If the pattern is refutable, then we need to handle
the \lstinline[language=Scala]!case! when the match is not
possible. Obviously, we just want to throw those away, so a
\lstinline[language=Scala]!fold! might be a better a better choice,
but then that obscures the correspondence.


\subsubsection{Decomposition of monad requirements}

In the presentation of the monad API that we've discussed here the
constraints on any given monad candidate are well factored into three
different kinds of requirements -- operating at different levels of
the ``API'', dubbed in order of abstraction: functoriality, naturality
and coherence. Often these can be mechanically verified, and when they
can't there are natural ways to generate spot-checks that fit well
with tools such as $\ScalaCheck$.

\subsubsection{A categorical way to look at monads}

One of the principle challenges of presenting the categorical view of
monads is the dependencies on the ambient theory. In some sense the
categorical view of the monad API is like a useful piece of software
that drags in a bunch of other libraries. A complete specification of
monad from the categorical point of view requires providing
definitions for

\begin{itemize}
  \item category
  \item functor
  \item natural transformation
\end{itemize}

This book is not intended to be a tutorial on category theory. There
are lots of those and Google and Wikipedia are your friends. Rather,
this book is about a certain design pattern that can be expressed, and
originally was expressed within that theory, but is to a great extent
an independent notion. \footnote{In point of fact, at present writing,
  i suspect that there is a way to turn category theory on its head
  and make the notion of monad the fundamental building block out of
  which the rest of category may be defined.} On the other hand, for
the diligent and/or curious reader a pointer to that body of work has
the potential to be quite rewarding. There are many treasures there
waiting to be found. For our purposes, we strike a compromise. We take
the notion of category to be given in terms of the definable types
within the \texttt{Scala} type system and the definable programs
(sometimes called maps) between those types. Then a functor, say
\lstinline[language=Scala,mathescape=true]!F$_T$! is a parametric type
constructor, together with a corresponding action, say
\lstinline[language=Scala,mathescape=true]!F$_M$!, on programs, that
respects certain invariants. Specifically,

\begin{itemize}
\item A functor must preserve identity. That is, for any type,
  \lstinline[language=Scala,mathescape=true]!A!, we can define an
  identity map, given canonically by the program
  \lstinline[language=Scala,mathescape=true]!( x : A ) => x!. Then
  \lstinline[language=Scala,mathescape=true]!F$_M$( ( x : A ) => x ) = ( x : F$_T$[A] ) => x!
  \item A functor must preserve composition. That is, given two programs, \lstinline[language=Scala,mathescape=true]!f : A => B! and \lstinline[language=Scala,mathescape=true]!g : B => C!, \lstinline[language=Scala,mathescape=true]!F$_M$( f $\circ$ g ) = F$_M$( f ) $\circ$ F$_M$( g )! where \lstinline[language=Scala,mathescape=true]! ( f $\circ$ g )( x ) = g( f( x ) )!
\end{itemize}

In \texttt{Scala}-land this is what it means for
\lstinline[language=Scala,mathescape=true]!F = (F$_T$,F$_M$)! to be
\emph{functorial}. The constraint itself is called
\emph{functoriality}. Sometimes we will refer to the tuple
\lstinline[language=Scala,mathescape=true]!(F$_T$,F$_M$)! just by
\lstinline[language=Scala,mathescape=true]!F! when there is little
risk of confusion.

From these operational definitions, it follows that a natural
transformation is map between functors! We expect it to be give in
terms of component maps. That is, at a type, say
\lstinline[language=Scala,mathescape=true]!A! a natural
transformation, \lstinline[language=Scala,mathescape=true]!n! from a
functor \lstinline[language=Scala,mathescape=true]!F! to a functor
\lstinline[language=Scala,mathescape=true]!G! should have a map
\lstinline[language=Scala,mathescape=true]!n$_A$ : F[A] => G[A]!.
These component maps need to satisfy some constraints. To wit,

\begin{itemize}
  \item Suppose we have a map \lstinline[language=Scala,mathescape=true]!f : A => B!. Then we want \lstinline[language=Scala,mathescape=true]!n$_A$ $\circ$ G( f ) = F( f ) $\circ$ n$_B$!.
\end{itemize}

As you might have guessed, this constraint is dubbed
\emph{naturality}. Category theorists have developed a nice
methodology for reasoning about such constraints. They draw them as
diagrams.

\begin{diagram}
  F[A] & \rTo^{n_A} & G[A] \\
  \dTo^{F(f)} & & \dTo_{G(f)} \\
  F[B] & \rTo_{n_B} & G[B]
\end{diagram}

Then a monad is really given by a triple, \lstinline[language=Scala,mathescape=true]!(S, unit, mult)! where 

\begin{itemize}
  \item \lstinline[language=Scala,mathescape=true]!S! is a functor, 
  \item \lstinline[language=Scala,mathescape=true]!unit! is a natural transformation from the identity functor to \lstinline[language=Scala,mathescape=true]!S!, 
  \item \lstinline[language=Scala,mathescape=true]!mult! is a natural transformation from \lstinline[language=Scala,mathescape=true]!S$^2$! to \lstinline[language=Scala,mathescape=true]!S!.
\end{itemize}

subject to the following constraints.

\begin{itemize}
\item \lstinline[language=Scala,mathescape=true]!mult $\circ$ S mult = mult $\circ$ mult S! %[mult-mult]
\item \lstinline[language=Scala,mathescape=true]!mult $\circ$ S unit = mult $\circ$ unit S! %[mult-unit]
\end{itemize}

Or in pictures

\begin{diagram}
  S^3 & \rTo^{S \; mult} & S^2 \\
  \dTo^{mult \; S} & & \dTo_{mult} \\
  S^2 & \rTo_{mult} & S
\end{diagram}

\begin{diagram}
  S & \rTo^{unit \; S} & S^2 \\
  \dTo^{S \; unit} & & \dTo_{mult} \\
  S^2 & \rTo_{mult} & S
\end{diagram}

which are really shorthand for

\begin{diagram}
  S[S[S[A]] & \rTo^{S( mult_A )} & S[S[A]] \\
  \dTo^{mult_{S[A]}} & & \dTo_{mult_A} \\
  S[S[A]] & \rTo_{mult_A} & S[A]
\end{diagram}

\begin{diagram}
  S[A] & \rTo^{unit_{S[A]}} & S[S[A]] \\
  \dTo^{S(unit_A)} & & \dTo_{mult_A} \\
  S[S[A]] & \rTo_{mult_A} & S[A]
\end{diagram}

\texttt{Scala} programmers can certainly understand these laws with a
little unpacking. [TBD]

Despite the apparent complexity the presentation has a certain
organization to it that is very natural once it becomes clear. There
are actually three different levels of constraints that follow a kind
of food-chain. At the level of \texttt{Scala}, which is our ambient
category, we find types and maps between them. Though this is harder
to see because we have restricted our view to just \emph{one}
category, at the level of functors, categories play in the role of
types, while functors play in the role of maps between them. At the
level of natural transformations, functors play in the role of types
while natural transformations play in the role of maps between
them. Monads bring all three levels together into one package. Monads
operate on a category via a functor and pair of natural
transformations.

% These two definitions are interchangeable. That's what makes them
% ``presentations'' of the same underlying idea.

% One of the reasons for the difference in presentation is that $\Haskell$
% doesn't treat the Monad type class as a Functor. The refactoring of
% the $mult$ map into the $bind$ map is that it builds functoriality
% into definition. The other reason is the do notation.






